import os
import logging
import json
import requests
import urllib.parse
import random
import re
import io
from PIL import Image  # Ù…ÙƒØªØ¨Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
from dotenv import load_dotenv
import google.generativeai as genai
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters

# Load environment variables
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GEMINI_API_KEYS = os.getenv("GEMINI_API_KEY", "").split(',')
DB_CHANNEL_ID = os.getenv("DB_CHANNEL_ID")

current_key_index = 0

def configure_genai():
    global current_key_index
    if not GEMINI_API_KEYS:
        logging.error("No GEMINI_API_KEYS found.")
        return None
    key = GEMINI_API_KEYS[current_key_index].strip()
    genai.configure(api_key=key)
    return key

def rotate_key():
    global current_key_index
    if len(GEMINI_API_KEYS) > 1:
        current_key_index = (current_key_index + 1) % len(GEMINI_API_KEYS)
        configure_genai()
        return True
    return False

# Configure Logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[logging.FileHandler("bot_log.txt", encoding='utf-8'), logging.StreamHandler()]
)

configure_genai()

def get_model():
    knowledge_path = os.path.join(os.path.dirname(__file__), 'knowledge_base.txt')
    try:
        with open(knowledge_path, 'r', encoding='utf-8') as f:
            knowledge = f.read()
    except FileNotFoundError:
        knowledge = "You are Dark AI."
    
    model = genai.GenerativeModel(
        model_name='gemini-2.5-flash',
        system_instruction=knowledge
    )
    return model

model = get_model()
chats = {}

# --- Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Pollinations) ---
async def generate_image_logic(prompt, chat_id, context, caption_text=""):
    enhanced_prompt = f"dark atmosphere, gloomy, hyperrealistic, 8k, cinematic lighting, {prompt}"
    pollinations_model = "flux" 
    
    encoded_prompt = urllib.parse.quote(enhanced_prompt)
    seed = random.randint(0, 999999)
    image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1024&height=1024&seed={seed}&model={pollinations_model}&nologo=true"

    try:
        await context.bot.send_photo(
            chat_id=chat_id,
            photo=image_url,
            caption=caption_text,
            parse_mode="Markdown"
        )
        return True
    except Exception as e:
        await context.bot.send_message(chat_id=chat_id, text=f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ù…: {e}")
        return False

# --- Persistence Layer ---
async def save_history(context: ContextTypes.DEFAULT_TYPE):
    if not DB_CHANNEL_ID: return
    data = {}
    for user_id, chat_session in chats.items():
        history = []
        for msg in chat_session.history:
            # Ù†ØªØ¬Ø§Ù‡Ù„ Ø­ÙØ¸ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØ± ÙÙŠ Ù…Ù„Ù Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ Ù†Ø­ÙØ¸ Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·
            parts_text = []
            for part in msg.parts:
                if part.text:
                    parts_text.append(part.text)
            if parts_text:
                history.append({"role": msg.role, "parts": parts_text})
        data[str(user_id)] = history
    try:
        try:
            chat = await context.bot.get_chat(chat_id=DB_CHANNEL_ID)
            if chat.pinned_message: await chat.pinned_message.delete()
        except: pass
        json_str = json.dumps(data, ensure_ascii=False, indent=2)
        document = json_str.encode('utf-8')
        message = await context.bot.send_document(
            chat_id=DB_CHANNEL_ID, document=document, filename=f"dark_backup.json", caption="Dark AI Memory"
        )
        await message.pin(disable_notification=True)
    except Exception as e:
        logging.error(f"Save error: {e}")

async def load_history(application):
    if not DB_CHANNEL_ID: return
    try:
        chat = await application.bot.get_chat(chat_id=DB_CHANNEL_ID)
        pinned = chat.pinned_message
        if not pinned or not pinned.document: return
        f = await pinned.document.get_file()
        byte_data = await f.download_as_bytearray()
        data = json.loads(byte_data.decode('utf-8'))
        for user_id, history_data in data.items():
            formatted = [{"role": m["role"], "parts": m["parts"]} for m in history_data]
            chats[int(user_id)] = model.start_chat(history=formatted)
        logging.info(f"Restored history.")
    except Exception as e:
        logging.error(f"Load error: {e}")

# --- Handlers ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text('Ø£Ù†Ø§ Dark AI.\nØ£Ø³Ù…Ø¹ÙƒØŒ Ø£Ø±Ø§ÙƒØŒ ÙˆØ£Ø¬Ø³Ø¯ Ø£ÙÙƒØ§Ø±Ùƒ.')

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    global model
    user_id = update.effective_user.id
    
    # 1. Ø§Ù„ØªØ­Ù‚Ù‚: Ù‡Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù†Øµ Ø£Ù… ØµÙˆØ±Ø©ØŸ
    message_content = [] # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙŠ Ø³Ù†Ø±Ø³Ù„Ù‡Ø§ Ù„Ù€ Gemini
    user_text = ""

    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØµÙˆØ±Ø©
    if update.message.photo:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø£Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø©
        photo_file = await update.message.photo[-1].get_file()
        image_bytes = await photo_file.download_as_bytearray()
        img = Image.open(io.BytesIO(image_bytes))
        
        message_content.append(img) # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù…Ø­ØªÙˆÙ‰
        
        # Ù„Ùˆ ÙÙŠÙ‡ ÙˆØµÙ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© (Caption)
        if update.message.caption:
            user_text = update.message.caption
            message_content.append(user_text)
        else:
            # Ù„Ùˆ Ù…ÙÙŠØ´ ÙˆØµÙØŒ Ù†Ø¹ØªØ¨Ø±Ù‡ Ø¨ÙŠØ·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            user_text = "Analyze this image."
            message_content.append("Ù…Ø§Ø°Ø§ ØªØ±Ù‰ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©ØŸ Ø­Ù„Ù„Ù‡Ø§ Ø¨Ø£Ø³Ù„ÙˆØ¨Ùƒ Ø§Ù„Ù…Ø¸Ù„Ù….")

    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù†Øµ ÙÙ‚Ø·
    elif update.message.text:
        user_text = update.message.text
        message_content.append(user_text)
    
    else:
        return # Ù„Ùˆ Ù…Ù„Ù ØµÙˆØªÙŠ Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ (Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„Ø§ Ù†Ø¯Ø¹Ù…Ù‡)

    if not model: return
    if user_id not in chats: chats[user_id] = model.start_chat(history=[])
    chat_session = chats[user_id]
    
    # Ø¥Ø±Ø³Ø§Ù„ Action Ù…Ù†Ø§Ø³Ø¨
    action = 'upload_photo' if update.message.photo else 'typing'
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=action)
    
    max_retries = len(GEMINI_API_KEYS)
    attempts = 0
    while attempts < max_retries:
        try:
            # 2. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Ù†Øµ + ØµÙˆØ±Ø©) Ù„Ù€ Gemini
            response = chat_session.send_message(message_content)
            ai_reply = response.text
            
            # 3. Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø±ÙŠ Ù„Ù„Ø±Ø³Ù… ///IMG: ... ///
            img_pattern = r"///IMG:(.*?)///"
            match = re.search(img_pattern, ai_reply, re.DOTALL)
            
            if match:
                prompt_to_draw = match.group(1).strip()
                clean_reply = re.sub(img_pattern, "", ai_reply).strip()
                
                if clean_reply:
                    await update.message.reply_text(clean_reply)
                
                wait_msg = await update.message.reply_text("ğŸ‘ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø¹Ù‚Ù„ÙŠ...")
                await generate_image_logic(prompt_to_draw, update.effective_chat.id, context)
                await context.bot.delete_message(chat_id=update.effective_chat.id, message_id=wait_msg.message_id)

            else:
                if len(ai_reply) > 4096:
                    for x in range(0, len(ai_reply), 4000):
                        await update.message.reply_text(ai_reply[x:x+4000])
                else:
                    await update.message.reply_text(ai_reply)

            # Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„ØªØ¯ÙˆÙŠØ± (Save History)
            # Ù…Ù„Ø§Ø­Ø¸Ø©: Gemini ÙŠØªØ°ÙƒØ± Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©ØŒ Ù„ÙƒÙ†Ù†Ø§ Ù„Ø§ Ù†Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ù…Ù„Ù JSON Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
            await save_history(context)
            
            if len(GEMINI_API_KEYS) > 1: rotate_key(); model = get_model()
            return

        except Exception as e:
            if "429" in str(e) or "quota" in str(e).lower():
                attempts += 1
                if attempts < max_retries and rotate_key():
                    model = get_model(); chats[user_id] = model.start_chat(history=chat_session.history); chat_session = chats[user_id]; continue
                await update.message.reply_text("âŒ Quota Exceeded.")
                return
            else: 
                logging.error(f"Error processing message: {e}")
                await update.message.reply_text(f"âŒ Error: {str(e)[:100]}")
                return

if __name__ == '__main__':
    if not TELEGRAM_TOKEN: exit(1)
    async def post_init(app: ApplicationBuilder): await load_history(app)
    application = ApplicationBuilder().token(TELEGRAM_TOKEN).post_init(post_init).build()
    
    application.add_handler(CommandHandler("start", start))
    # ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙÙ„ØªØ± Ù„ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ
    application.add_handler(MessageHandler((filters.TEXT | filters.PHOTO) & ~filters.COMMAND, handle_message))
    
    print("Dark AI (Vision & Creation) is online...")
    application.run_polling()